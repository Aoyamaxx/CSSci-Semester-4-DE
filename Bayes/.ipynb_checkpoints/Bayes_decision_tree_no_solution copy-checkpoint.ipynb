{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Workshop VII** <br/> *Bayesian inference and decision trees*\n",
    "\n",
    "In this exercise, please fill in the blanks that indicated by ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import beta, norm, bernoulli\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from decimal import Decimal\n",
    "\n",
    "import ID3  # decision tree module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.** Bayesian Basics\n",
    "\n",
    "This first exercise is meant as an introduction to the Bayesian framework. In particular, we will simulate a dataset of disease contamination. By simulating the dataset, we know the \"true\" parameter values and we can thus examine how accurate our inferences are. To get started, lets set up the simulation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate a population of 100,000 people:\n",
    "population = 100_000\n",
    "prevalence = 0.01   # disease prevalence\n",
    "sensitivity = 0.95  # true positive rate\n",
    "specificity = 0.90  # true negative rate\n",
    "\n",
    "# infectious status (1 = infected, 0 = not infected):\n",
    "population_status = np.random.choice([1, 0], size=population, p=[prevalence, 1-prevalence])\n",
    "\n",
    "# assign some fictitious test results to the population, based on our sensitivity and specificity:\n",
    "test_results = np.zeros(population)\n",
    "for i in range(population):\n",
    "    if population_status[i] == 1:\n",
    "        test_results[i] = np.random.choice([1, 0], p=[sensitivity, 1-sensitivity])\n",
    "    else:\n",
    "        test_results[i] = np.random.choice([1, 0], p=[1-specificity, specificity])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to store the population data:\n",
    "df = pd.DataFrame({'status': population_status, 'test_result': test_results})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, assuming that we have access to both the test results and the true results (the \"status\"), try to extract the Baysian probabilities from our simulated data, to find out posterior probability of being infected, given a positive test result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Bayesian probabilities:\n",
    "prior_probability = ...\n",
    "likelihood = ...\n",
    "probability_testing_positive = ...\n",
    "\n",
    "print('Prior probability of infection:', prior_probability)\n",
    "print('Likelihood of testing positive given infection:', likelihood)\n",
    "print('Probability of testing positive:', probability_testing_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete the function to calculate posterior, and them use it to get the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian inference of Pr(status=1 | test=1)\n",
    "def bayes_theorem(prior, likelihood, evidence):\n",
    "    return ...\n",
    "\n",
    "pr_infected_given_positive = ...\n",
    "\n",
    "# print posterior. which is (Pr(test=1 | status=1) * Pr(status=1)) / Pr(test=1)\n",
    "print('Pr(status=1 | test=1) = ', pr_infected_given_positive) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpret your finding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If sensitivity is increased to 0.999, the specificity remains as original, what is the value of Pr(status=1 | test=1)?\n",
    "\n",
    "#### If specificity is increased to 0.999, the sensitivity remains as original, what is the value of Pr(status=1 | test=1)?\n",
    "\n",
    "#### Interprete your finding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.** Dealing with Uncertainty\n",
    "\n",
    "Of course, we are never able to take a peak into the true population parameters in real life. There will always be uncertainty. So far you have tried to quantify this uncertainty using frequentist techniques (i.e. maximum likelihood estimations, etc). Today you will quantify your uncertainty differently, using Bayesian statistics.\n",
    "\n",
    "In the following, you will try to use Bayesian inference to go from data to results.\n",
    "\n",
    "Now suppose we want to estimate the average weight of fish in a fishery farm. The real average weight of the fish is 2 kg. but we do not know this value beforehand. After a number of catches, we get data on the weight of a batch of fish. We know that the weights of the detected fish obeys a normal distribution around the mean value. How can we obtain the actual average weight of the fish from this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by adding some small data that obeys normal distribution. The mean is set to be 2 and the standard deviation is 1.\n",
    "\n",
    "The Data generated from the following code:\n",
    "\n",
    "#np.random.seed = 39\n",
    "\n",
    "#sample_data = np.random.normal(2, 1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = np.array([ 1.64350291,  0.87752135,  3.05569158,  1.48274427,  1.4059861 ,\n",
    "        3.93554187,  0.53890017,  2.12058382,  0.54360397,  2.25308647,\n",
    "        2.71833633,  2.11059019,  0.90982909,  3.10162428,  2.99375448,\n",
    "        1.9048221 ,  2.25047556,  2.60237373,  1.59678977,  2.00217239,\n",
    "        1.3469326 ,  1.05712171,  0.32794892,  3.36094034, -0.42828078,\n",
    "        1.27685994,  2.84693071,  3.21779923,  0.15080283,  2.29198599])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, because we cannot obtain the true value anymore, we set up a *prior distribution* to represent our uncertainty. \n",
    "\n",
    "Set up 4 priors to compare their effect on the posterior distribution later. Use the population value obtained in the previous part (i.e. approximately 0.0.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.linspace(1,3,100)\n",
    "\n",
    "# Prior 1: uncertain\n",
    "prior1 = beta.pdf(x_range/3.0, 1, 1)/3.0\n",
    "\n",
    "# Prior 2: somewhat uncertain\n",
    "prior2 = beta.pdf(x_range/3.0, 1, 3)/3.0\n",
    "\n",
    "# Prior 3: somewhat certain\n",
    "prior3 = beta.pdf(x_range/3.0, 5, 3)/3.0\n",
    "\n",
    "# Prior 4: certain\n",
    "prior4 = beta.pdf(x_range/3.0, 30, 15)/3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prior, title in zip([prior1, prior2, prior3, prior4], ['Uncertain', 'Somewhat uncertain', 'Somewhat certain', 'Certain']):\n",
    "    plt.plot(x_range, prior, label=title)\n",
    "\n",
    "plt.xlabel('Probability of infection')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Priors')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equiped with the prior distributions, we now form the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply log elements together\n",
    "def multiply_elements(array):\n",
    "    return np.log(array).sum()\n",
    "\n",
    "# computing exponential function and normalization for large value\n",
    "def largeExpNormalize(x_range,loglikelihoodlist):\n",
    "    declikelihood = [Decimal(k).exp() for k in loglikelihoodlist]\n",
    "    \n",
    "    surface = Decimal(0)\n",
    "    for i in range(1,len(x_range)):\n",
    "        surface += Decimal(x_range[i]-x_range[i-1])*declikelihood[i]        \n",
    "    \n",
    "    mlh = [float(k/surface) for k in declikelihood]\n",
    "    return mlh\n",
    "\n",
    "# Gaussian pdf\n",
    "def loglikelihood_function_normal(data,miu,sigma):\n",
    "    return multiply_elements(norm.pdf(data, miu, sigma))\n",
    "\n",
    "# compute likelihood\n",
    "mlh = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_range, mlh)\n",
    "plt.scatter(x_range[np.argmax(mlh)], mlh[np.argmax(mlh)], color='red',label=\"max %.4f\"%(x_range[np.argmax(mlh)]))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the posterior with prior 1-4 and plot them. A function to compute the area under the curve is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSurface(x,y):\n",
    "    surface = 0\n",
    "    for i in range(1,len(x)):\n",
    "        surface += (x[i]-x[i-1])*y[i]        \n",
    "    return surface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = ...\n",
    "# plot..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the above plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Trees: ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will use the provided `ID3.py` algorithm implementation to build and interpret a decision tree classifier. Apply this classifier to a real-world dataset, perform some predictions, and then analyze the decision tree's structure.\n",
    "\n",
    "Information on the variables in this dataset:\n",
    "1. age: age in years\n",
    "2. sex: sex (1 = male; 0 = female)\n",
    "3. cp: chest pain type:\n",
    "    - Value 1: typical angina\n",
    "    - Value 2: atypical angina\n",
    "    - Value 3: non-anginal pain\n",
    "    - Value 4: asymptomatic\n",
    "4. trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "5. chol: serum cholestoral in mg/dl\n",
    "6. fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "7. restecg: resting electrocardiographic results\n",
    "    - Value 0: normal\n",
    "    - Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "    - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "8. thalach: maximum heart rate achieved   \n",
    "9. exang: exercise induced angina (1 = yes; 0 = no)\n",
    "10. oldpeak = ST depression induced by exercise relative to rest\n",
    "11. slope: the slope of the peak exercise ST segment\n",
    "    - Value 1: upsloping\n",
    "    - Value 2: flat\n",
    "    - Value 3: downsloping\n",
    "12. ca: number of major vessels (0-3) colored by flourosopy        \n",
    "13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "14. num: diagnosis of heart disease (angiographic disease status)\n",
    "    - Value 0: < 50% diameter narrowing, which is no disease.\n",
    "    - Value more than 0: > 50% diameter narrowing (in any major vessel), which indicates disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the \"Heart Disease UCI\" dataset & remove missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data & add column names\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
    "    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'\n",
    "]\n",
    "df = pd.read_csv('processed.cleveland.data', names=column_names, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the continuous attributes into categorical ones. We need to do for attributes age, trestbps, chol, thalach, oldpeak, cp, sec, slope, thal and num. The first two are already done.\n",
    "\n",
    "Note that there are many ways to do the discretization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning 'age' into categories\n",
    "bins_age = [0, 30, 40, 50, 60, 70, 120]\n",
    "labels_age = ['below 30', '30-39', '40-49', '50-59', '60-69', 'above 70']\n",
    "df['age'] = pd.cut(df['age'], bins=bins_age, labels=labels_age, include_lowest=True)\n",
    "\n",
    "# Binning 'trestbps' (resting blood pressure) into categories\n",
    "bins_trestbps = [0, 120, 140, 160, 180, 200]\n",
    "labels_trestbps = ['below 120', '121-140', '141-160', '161-180', 'above 180']\n",
    "df['trestbps'] = pd.cut(df['trestbps'], bins=bins_trestbps, labels=labels_trestbps, include_lowest=True)\n",
    "\n",
    "# Binning 'chol' (serum cholesterol) into categories\n",
    "...\n",
    "\n",
    "# Binning 'thalach' (maximum heart rate achieved) into categories\n",
    "...\n",
    "\n",
    "# Binning 'oldpeak' (ST depression induced by exercise relative to rest) into categories\n",
    "...\n",
    "\n",
    "# Giving cp (chest pain type) more descriptive names\n",
    "...\n",
    "\n",
    "# Giving sex more descriptive names\n",
    "...\n",
    "\n",
    "# Giving slope (the slope of the peak exercise ST segment) more descriptive names\n",
    "...\n",
    "\n",
    "# Giving thal (thalium stress test result) more descriptive names\n",
    "...\n",
    "\n",
    "# Giving num (diagnosis of heart disease) more descriptive names\n",
    "...\n",
    "\n",
    "# Turn the rest into string\n",
    "df = df.astype(str)\n",
    "\n",
    "# show\n",
    "print([type(df.iloc[0,i]) for i in range(len(df.columns))])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "data_train, data_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, using the provided ID3 algorithm, construct a decision tree using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the decision tree from the provided ID3 algorithm\n",
    "decision_tree = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the tree to get an idea of its structure\n",
    "ID3.print_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement a code to use the constructed decision tree to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'class' column should not be included in the features of the test set\n",
    "test_features = ...\n",
    "actual_values = ...\n",
    "\n",
    "# Use the new prediction function to get predictions for the test set\n",
    "# default value is used when no result is obtained\n",
    "predictions = ...\n",
    "\n",
    "# Compare the predictions with the actual values\n",
    "comparison = pd.DataFrame({'Actual': actual_values, 'Predicted': predictions})\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualize the accuracy!\n",
    "accuracy = accuracy_score(actual_values, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(actual_values, predictions)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\", xticklabels=['Predicted No', 'Predicted Yes'], yticklabels=['Actual No', 'Actual Yes'])\n",
    "plt.title('Confusion Matrix')\n",
    "#plt.xlabel('Predicted Label')\n",
    "#plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, interpret your decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID3.print_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.** Decision Trees: CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we try to use the python build-in function, CART.\n",
    "\n",
    "For this method, we don't need to categorize our attributes. While the non-categorical attributes works better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data\n",
    "df = pd.read_csv('processed.cleveland.data', names=column_names, header=None)\n",
    "df.replace('?', np.nan, inplace=True)  # missing entries are marked with '?'\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df.drop('num', axis=1)  # features\n",
    "y = df['num']  # target\n",
    "\n",
    "# Split the dataset into training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print([type(X_train.iloc[0,i]) for i in range(len(X_train.columns))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a decision tree and fit the data into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DecisionTreeClassifier object\n",
    "cart_model = ...\n",
    "\n",
    "# Fit the model to the training data\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's make some predictions on the test set to evaluate performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "predictions = ...\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = ...\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate and plot the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1, 2, 3, 4], yticklabels=[0, 1, 2, 3, 4])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we visualize the decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(cart_model, \n",
    "          filled=True, \n",
    "          rounded=True, \n",
    "          class_names=['0', '1', '2', '3', '4'],  # Update class names as appropriate\n",
    "          feature_names=list(X_train.columns))       # Ensure X_train.columns is accessible\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please interpret the results, try to answer the following:\n",
    "\n",
    "- How well did both models predict heart disease presence?\n",
    "- Describe the model's performance in terms of false positives, false negatives, true positives, and true negatives.\n",
    "- Analyze the tree to determine the most important features and decision paths leading to heart disease prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_homebrew_kernel",
   "language": "python",
   "name": "my_homebrew_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
